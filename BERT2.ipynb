{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT2.ipynb","provenance":[],"authorship_tag":"ABX9TyODTzci4frnBxk3r5ErBLau"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2N051VHi5RT9","executionInfo":{"status":"ok","timestamp":1651614561320,"user_tz":300,"elapsed":6568,"user":{"displayName":"Saba Yousefian","userId":"17735402963118911033"}},"outputId":"6503e7f7-abcd-4a90-e6b6-63b998a2997e"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n","Cloning into 'models'...\n","remote: Enumerating objects: 752, done.\u001b[K\n","remote: Counting objects: 100% (752/752), done.\u001b[K\n","remote: Compressing objects: 100% (651/651), done.\u001b[K\n","remote: Total 752 (delta 166), reused 372 (delta 91), pack-reused 0\u001b[K\n","Receiving objects: 100% (752/752), 1.22 MiB | 10.83 MiB/s, done.\n","Resolving deltas: 100% (166/166), done.\n","Note: checking out '47e65c1aedf4181faaf5535f06c26dbcb083c4ad'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by performing another checkout.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -b with the checkout command again. Example:\n","\n","  git checkout -b <new-branch-name>\n","\n"]}],"source":["import tensorflow as tf\n","print(tf.version.VERSION)\n","!git clone --depth 1 -b v2.4.0 https://github.com/tensorflow/models.git"]},{"cell_type":"code","source":["# install requirements to use tensorflow/models repository\n","!pip install -Uqr models/official/requirements.txt\n","# you may have to restart the runtime afterwards, also ignore any ERRORS popping up at this step"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bzrynKPF5Y5O","executionInfo":{"status":"ok","timestamp":1651614657865,"user_tz":300,"elapsed":59257,"user":{"displayName":"Saba Yousefian","userId":"17735402963118911033"}},"outputId":"11890176-7bd2-40c5-f4e1-112f05c7b69f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 8.4 MB 28.3 MB/s \n","\u001b[K     |████████████████████████████████| 210 kB 55.2 MB/s \n","\u001b[K     |████████████████████████████████| 280 kB 49.6 MB/s \n","\u001b[K     |████████████████████████████████| 99 kB 7.3 MB/s \n","\u001b[K     |████████████████████████████████| 38.1 MB 313 kB/s \n","\u001b[K     |████████████████████████████████| 237 kB 61.0 MB/s \n","\u001b[K     |████████████████████████████████| 4.2 MB 30.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 51.9 MB/s \n","\u001b[K     |████████████████████████████████| 352 kB 61.8 MB/s \n","\u001b[K     |████████████████████████████████| 11.2 MB 36.0 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 70.5 MB/s \n","\u001b[K     |████████████████████████████████| 47.8 MB 1.3 MB/s \n","\u001b[K     |████████████████████████████████| 4.3 MB 31.9 MB/s \n","\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 41.7 MB/s \n","\u001b[K     |████████████████████████████████| 180 kB 45.8 MB/s \n","\u001b[K     |████████████████████████████████| 76 kB 4.1 MB/s \n","\u001b[K     |████████████████████████████████| 46 kB 2.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.0 MB 46.3 MB/s \n","\u001b[K     |████████████████████████████████| 930 kB 59.7 MB/s \n","\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 3.0.1 which is incompatible.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","google-cloud-translate 1.5.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.3.0 which is incompatible.\n","google-cloud-storage 1.18.1 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.3.0 which is incompatible.\n","google-cloud-storage 1.18.1 requires google-resumable-media<0.5.0dev,>=0.3.1, but you have google-resumable-media 2.3.2 which is incompatible.\n","google-cloud-firestore 1.7.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.3.0 which is incompatible.\n","google-cloud-datastore 1.8.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.3.0 which is incompatible.\n","earthengine-api 0.1.306 requires google-api-python-client<2,>=1.12.1, but you have google-api-python-client 2.47.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"]}]},{"cell_type":"code","source":["!pip install seaborn"],"metadata":{"id":"lf3oHmMt6UXv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install wandb"],"metadata":{"id":"uI-cknIA7ZnC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import sys\n","sys.path.append('models')\n","# from official.nlp.data import classifier_data_lib\n","# from official.nlp.bert import tokenization\n","# from official.nlp import optimization\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import scipy\n","# import seaborn as sns\n","# sns.set()\n","import wandb\n","from wandb.keras import WandbCallback"],"metadata":{"id":"nIeOa_CH5yYp","executionInfo":{"status":"ok","timestamp":1651615073842,"user_tz":300,"elapsed":869,"user":{"displayName":"Saba Yousefian","userId":"17735402963118911033"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["print(\"TF Version: \", tf.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"Hub version: \", hub.__version__)\n","print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_31qXe6S7lBw","executionInfo":{"status":"ok","timestamp":1651615141997,"user_tz":300,"elapsed":172,"user":{"displayName":"Saba Yousefian","userId":"17735402963118911033"}},"outputId":"71fa6e74-f275-4b65-aeda-520e937d4133"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["TF Version:  2.8.0\n","Eager mode:  True\n","Hub version:  0.12.0\n","GPU is NOT AVAILABLE\n"]}]},{"cell_type":"code","source":["# TO LOAD DATA \n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","df = pd.read_csv('/content/gdrive/MyDrive/Spring2022/gender-detection/tweets/train_2.csv')\n","print(df.shape)\n","df.head(10)\n","# label 0 == male\n","# label 1 == female "],"metadata":{"id":"TB2ebNv676wC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Average word length of questions in dataset is {0:.0f}.'.format(np.mean(df['question_text'].apply(lambda x: len(x.split())))))\n","print('Max word length of questions in dataset is {0:.0f}.'.format(np.max(df['question_text'].apply(lambda x: len(x.split())))))\n","print('Average character length of questions in dataset is {0:.0f}.'.format(np.mean(df['question_text'].apply(lambda x: len(x)))))"],"metadata":{"id":"JLkBZnHk8UId"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df, remaining = train_test_split(df, random_state=﻿42﻿, train_size=﻿0.1﻿, stratify=df.target.values)\n","valid_df, _ = train_test_split(remaining, random_state=﻿42﻿, train_size=﻿0.01﻿, stratify=remaining.target.values)\n","print﻿(train_df.shape)\n","print﻿(valid_df.shape) "],"metadata":{"id":"kc9QbXJR8vQx"},"execution_count":null,"outputs":[]}]}